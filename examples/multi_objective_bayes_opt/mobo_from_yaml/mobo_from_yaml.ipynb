{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Multi-objective Bayesian Optimization\n",
    "\n",
    "\n",
    "TNK function\n",
    "$n=2$ variables:\n",
    "$x_i \\in [0, \\pi], i=1,2$\n",
    "\n",
    "Objectives:\n",
    "- $f_i(x) = x_i$\n",
    "\n",
    "Constraints:\n",
    "- $g_1(x) = -x_1^2 -x_2^2 + 1 + 0.1 \\cos\\left(16 \\arctan \\frac{x_1}{x_2}\\right) \\le 0$\n",
    "- $g_2(x) = (x_1 - 1/2)^2 + (x_2-1/2)^2 \\le 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-07-02T04:15:10.015133Z",
     "iopub.status.busy": "2022-07-02T04:15:10.014749Z",
     "iopub.status.idle": "2022-07-02T04:15:10.685098Z",
     "shell.execute_reply": "2022-07-02T04:15:10.684416Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "NUM_STEPS = 2 if SMOKE_TEST else 50\n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from xopt import Xopt\n",
    "\n",
    "\n",
    "YAML = \"\"\"\n",
    "generator:\n",
    "    name: mobo\n",
    "    reference_point: {y1: 1.5, y2: 1.5}\n",
    "\n",
    "evaluator:\n",
    "    function: xopt.resources.test_functions.tnk.evaluate_TNK\n",
    "\n",
    "vocs:\n",
    "    variables:\n",
    "        x1: [0, 3.14159]\n",
    "        x2: [0, 3.14159]\n",
    "    objectives: {y1: MINIMIZE, y2: MINIMIZE}\n",
    "    constraints:\n",
    "        c1: [GREATER_THAN, 0]\n",
    "        c2: [LESS_THAN, 0.5]\n",
    "    constants: {a: dummy_constant}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-07-02T04:15:10.687362Z",
     "iopub.status.busy": "2022-07-02T04:15:10.687067Z",
     "iopub.status.idle": "2022-07-02T04:15:43.551401Z",
     "shell.execute_reply": "2022-07-02T04:15:43.551074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(NUM_STEPS):\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(i)\n\u001B[1;32m----> 5\u001B[0m     \u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\base.py:217\u001B[0m, in \u001B[0;36mXopt.step\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;66;03m# generate samples and submit to evaluator\u001B[39;00m\n\u001B[0;32m    216\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_generate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m candidates\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 217\u001B[0m new_samples \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_generate\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    219\u001B[0m \u001B[38;5;66;03m# generator is done when it returns no new samples\u001B[39;00m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(new_samples) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\bayesian_generator.py:80\u001B[0m, in \u001B[0;36mBayesianGenerator.generate\u001B[1;34m(self, n_candidates)\u001B[0m\n\u001B[0;32m     76\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocs\u001B[38;5;241m.\u001B[39mrandom_inputs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mn_initial)\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;66;03m# update internal model with internal data\u001B[39;00m\n\u001B[1;32m---> 80\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;66;03m# calculate optimization bounds\u001B[39;00m\n\u001B[0;32m     83\u001B[0m     bounds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_optimization_bounds()\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\bayesian_generator.py:106\u001B[0m, in \u001B[0;36mBayesianGenerator.train_model\u001B[1;34m(self, data, update_internal)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data\u001B[38;5;241m.\u001B[39mempty:\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno data available to build model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 106\u001B[0m _model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgp_constructor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;66;03m# validate returned model\u001B[39;00m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_model(_model)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\models\\standard.py:60\u001B[0m, in \u001B[0;36mStandardModelConstructor.build_model\u001B[1;34m(self, data, tkwargs)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollect_data(data)\n\u001B[0;32m     59\u001B[0m \u001B[38;5;66;03m# build model\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild_standard_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\models\\standard.py:98\u001B[0m, in \u001B[0;36mStandardModelConstructor.build_standard_model\u001B[1;34m(self, **model_kwargs)\u001B[0m\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mean_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     93\u001B[0m         mean_module \u001B[38;5;241m=\u001B[39m CustomMean(\n\u001B[0;32m     94\u001B[0m             mean_module, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_transform, outcome_transform\n\u001B[0;32m     95\u001B[0m         )\n\u001B[0;32m     97\u001B[0m     models\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m---> 98\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild_single_task_gp\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     99\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_X\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    100\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtrain_Y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    101\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_transform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    102\u001B[0m \u001B[43m            \u001B[49m\u001B[43moutcome_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutcome_transform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcovar_module\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcovar_module\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    104\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmean_module\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmean_module\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    105\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlikelihood\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlikelihood\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    107\u001B[0m     )\n\u001B[0;32m    109\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ModelListGP(\u001B[38;5;241m*\u001B[39mmodels)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\base_model.py:37\u001B[0m, in \u001B[0;36mModelConstructor.build_single_task_gp\u001B[1;34m(train_X, train_Y, **kwargs)\u001B[0m\n\u001B[0;32m     34\u001B[0m model \u001B[38;5;241m=\u001B[39m SingleTaskGP(train_X, train_Y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     36\u001B[0m mll \u001B[38;5;241m=\u001B[39m ExactMarginalLogLikelihood(model\u001B[38;5;241m.\u001B[39mlikelihood, model)\n\u001B[1;32m---> 37\u001B[0m \u001B[43mfit_gpytorch_mll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmll\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\botorch\\fit.py:105\u001B[0m, in \u001B[0;36mfit_gpytorch_mll\u001B[1;34m(mll, closure, optimizer, closure_kwargs, optimizer_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m optimizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# defer to per-method defaults\u001B[39;00m\n\u001B[0;32m    103\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m optimizer\n\u001B[1;32m--> 105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m FitGPyTorchMLL(\n\u001B[0;32m    106\u001B[0m     mll,\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28mtype\u001B[39m(mll\u001B[38;5;241m.\u001B[39mlikelihood),\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;28mtype\u001B[39m(mll\u001B[38;5;241m.\u001B[39mmodel),\n\u001B[0;32m    109\u001B[0m     closure\u001B[38;5;241m=\u001B[39mclosure,\n\u001B[0;32m    110\u001B[0m     closure_kwargs\u001B[38;5;241m=\u001B[39mclosure_kwargs,\n\u001B[0;32m    111\u001B[0m     optimizer_kwargs\u001B[38;5;241m=\u001B[39moptimizer_kwargs,\n\u001B[0;32m    112\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    113\u001B[0m )\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\botorch\\utils\\dispatcher.py:93\u001B[0m, in \u001B[0;36mDispatcher.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     91\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(types\u001B[38;5;241m=\u001B[39mtypes)\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MDNotImplementedError:\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;66;03m# Traverses registered methods in order, yields whenever a match is found\u001B[39;00m\n\u001B[0;32m     96\u001B[0m     funcs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_iter(\u001B[38;5;241m*\u001B[39mtypes)\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\botorch\\fit.py:252\u001B[0m, in \u001B[0;36m_fit_fallback\u001B[1;34m(mll, _, __, closure, optimizer, closure_kwargs, optimizer_kwargs, max_attempts, warning_handler, caught_exception_types, **ignore)\u001B[0m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m catch_warnings(record\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m warning_list, debug(\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m    251\u001B[0m     simplefilter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malways\u001B[39m\u001B[38;5;124m\"\u001B[39m, category\u001B[38;5;241m=\u001B[39mOptimizationWarning)\n\u001B[1;32m--> 252\u001B[0m     optimizer(mll, closure\u001B[38;5;241m=\u001B[39mclosure, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptimizer_kwargs)\n\u001B[0;32m    254\u001B[0m \u001B[38;5;66;03m# Resolved warnings and determine whether or not to retry\u001B[39;00m\n\u001B[0;32m    255\u001B[0m done \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\botorch\\optim\\fit.py:120\u001B[0m, in \u001B[0;36mfit_gpytorch_mll_scipy\u001B[1;34m(mll, parameters, bounds, closure, closure_kwargs, method, options, callback, timeout_sec)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m closure_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    118\u001B[0m     closure \u001B[38;5;241m=\u001B[39m partial(closure, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mclosure_kwargs)\n\u001B[1;32m--> 120\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mscipy_minimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    124\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_sec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_sec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m!=\u001B[39m OptimizationStatus\u001B[38;5;241m.\u001B[39mSUCCESS:\n\u001B[0;32m    130\u001B[0m     warn(\n\u001B[0;32m    131\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`scipy_minimize` terminated with status \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;241m.\u001B[39mstatus\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, displaying\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    132\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m original message from `scipy.optimize.minimize`: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    133\u001B[0m         OptimizationWarning,\n\u001B[0;32m    134\u001B[0m     )\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\botorch\\optim\\core.py:109\u001B[0m, in \u001B[0;36mscipy_minimize\u001B[1;34m(closure, parameters, bounds, callback, x0, method, options, timeout_sec)\u001B[0m\n\u001B[0;32m    101\u001B[0m         result \u001B[38;5;241m=\u001B[39m OptimizationResult(\n\u001B[0;32m    102\u001B[0m             step\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mnext\u001B[39m(call_counter),\n\u001B[0;32m    103\u001B[0m             fval\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m(wrapped_closure(x)[\u001B[38;5;241m0\u001B[39m]),\n\u001B[0;32m    104\u001B[0m             status\u001B[38;5;241m=\u001B[39mOptimizationStatus\u001B[38;5;241m.\u001B[39mRUNNING,\n\u001B[0;32m    105\u001B[0m             runtime\u001B[38;5;241m=\u001B[39mmonotonic() \u001B[38;5;241m-\u001B[39m start_time,\n\u001B[0;32m    106\u001B[0m         )\n\u001B[0;32m    107\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m callback(parameters, result)  \u001B[38;5;66;03m# pyre-ignore [29]\u001B[39;00m\n\u001B[1;32m--> 109\u001B[0m raw \u001B[38;5;241m=\u001B[39m \u001B[43mminimize_with_timeout\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwrapped_closure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    111\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwrapped_closure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp_float64\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    113\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds_np\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    115\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwrapped_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_sec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_sec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;66;03m# Post-processing and outcome handling\u001B[39;00m\n\u001B[0;32m    121\u001B[0m wrapped_closure\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m asarray(raw\u001B[38;5;241m.\u001B[39mx)  \u001B[38;5;66;03m# set parameter state to optimal values\u001B[39;00m\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\botorch\\optim\\utils\\timeout.py:80\u001B[0m, in \u001B[0;36mminimize_with_timeout\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001B[0m\n\u001B[0;32m     77\u001B[0m     wrapped_callback \u001B[38;5;241m=\u001B[39m callback\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 80\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moptimize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     85\u001B[0m \u001B[43m        \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhess\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhessp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhessp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconstraints\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconstraints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     91\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwrapped_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m OptimizationTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     95\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimization timed out after \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;241m.\u001B[39mruntime\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\scipy\\optimize\\_minimize.py:696\u001B[0m, in \u001B[0;36mminimize\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[0;32m    693\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[0;32m    694\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    695\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml-bfgs-b\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 696\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001B[0;32m    697\u001B[0m                            callback\u001B[38;5;241m=\u001B[39mcallback, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtnc\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    699\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[0;32m    700\u001B[0m                         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:359\u001B[0m, in \u001B[0;36m_minimize_lbfgsb\u001B[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001B[0m\n\u001B[0;32m    353\u001B[0m task_str \u001B[38;5;241m=\u001B[39m task\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[0;32m    354\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFG\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    355\u001B[0m     \u001B[38;5;66;03m# The minimization routine wants f and g at the current x.\u001B[39;00m\n\u001B[0;32m    356\u001B[0m     \u001B[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001B[39;00m\n\u001B[0;32m    357\u001B[0m     \u001B[38;5;66;03m# until the completion of the current minimization iteration.\u001B[39;00m\n\u001B[0;32m    358\u001B[0m     \u001B[38;5;66;03m# Overwrite f and g:\u001B[39;00m\n\u001B[1;32m--> 359\u001B[0m     f, g \u001B[38;5;241m=\u001B[39m \u001B[43mfunc_and_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNEW_X\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    361\u001B[0m     \u001B[38;5;66;03m# new iteration\u001B[39;00m\n\u001B[0;32m    362\u001B[0m     n_iterations \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001B[0m, in \u001B[0;36mScalarFunction.fun_and_grad\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray_equal(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx):\n\u001B[0;32m    284\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_x_impl(x)\n\u001B[1;32m--> 285\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    286\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_grad()\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001B[0m, in \u001B[0;36mScalarFunction._update_fun\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_fun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    250\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated:\n\u001B[1;32m--> 251\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    252\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.update_fun\u001B[1;34m()\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_fun\u001B[39m():\n\u001B[1;32m--> 155\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[43mfun_wrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnfev \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;66;03m# Send a copy because the user may overwrite it.\u001B[39;00m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;66;03m# Overwriting results in undefined behaviour because\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001B[39;00m\n\u001B[1;32m--> 137\u001B[0m fx \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;66;03m# Make sure the function returns a true scalar\u001B[39;00m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(fx):\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\scipy\\optimize\\_optimize.py:76\u001B[0m, in \u001B[0;36mMemoizeJac.__call__\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m     75\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" returns the function value \"\"\"\u001B[39;00m\n\u001B[1;32m---> 76\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_if_needed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\scipy\\optimize\\_optimize.py:70\u001B[0m, in \u001B[0;36mMemoizeJac._compute_if_needed\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(x \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m---> 70\u001B[0m     fg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     71\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\botorch\\optim\\closures\\core.py:150\u001B[0m, in \u001B[0;36mNdarrayOptimizationClosure.__call__\u001B[1;34m(self, state, **kwargs)\u001B[0m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m state\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m     value_tensor, grad_tensors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclosure(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mas_array(value_tensor)\n\u001B[0;32m    152\u001B[0m     grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_gradient_ndarray(fill_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfill_value)\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\botorch\\optim\\closures\\core.py:66\u001B[0m, in \u001B[0;36mForwardBackwardClosure.__call__\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m     64\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     65\u001B[0m value \u001B[38;5;241m=\u001B[39m values \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreducer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreducer(values)\n\u001B[1;32m---> 66\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(param\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;28;01mfor\u001B[39;00m param \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback:\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "X = Xopt.from_yaml(YAML)\n",
    "\n",
    "# for testing purposes only\n",
    "if SMOKE_TEST:\n",
    "    X.generator.numerical_optimizer.n_restarts = 1\n",
    "    X.generator.n_monte_carlo_samples = 1\n",
    "\n",
    "X.random_evaluate(5)\n",
    "for i in range(NUM_STEPS):\n",
    "    print(i)\n",
    "    X.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-07-02T04:15:43.553277Z",
     "iopub.status.busy": "2022-07-02T04:15:43.553163Z",
     "iopub.status.idle": "2022-07-02T04:15:43.571308Z",
     "shell.execute_reply": "2022-07-02T04:15:43.571042Z"
    }
   },
   "outputs": [],
   "source": [
    "X.generator.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## plot results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-07-02T04:15:43.572903Z",
     "iopub.status.busy": "2022-07-02T04:15:43.572794Z",
     "iopub.status.idle": "2022-07-02T04:15:43.925991Z",
     "shell.execute_reply": "2022-07-02T04:15:43.925670Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "theta = np.linspace(0, np.pi / 2)\n",
    "r = np.sqrt(1 + 0.1 * np.cos(16 * theta))\n",
    "x_1 = r * np.sin(theta)\n",
    "x_2_lower = r * np.cos(theta)\n",
    "x_2_upper = (0.5 - (x_1 - 0.5) ** 2) ** 0.5 + 0.5\n",
    "\n",
    "z = np.zeros_like(x_1)\n",
    "\n",
    "# ax2.plot(x_1, x_2_lower,'r')\n",
    "ax.fill_between(x_1, z, x_2_lower, fc=\"white\")\n",
    "circle = plt.Circle(\n",
    "    (0.5, 0.5), 0.5 ** 0.5, color=\"r\", alpha=0.25, zorder=0, label=\"Valid Region\"\n",
    ")\n",
    "ax.add_patch(circle)\n",
    "history = pd.concat(\n",
    "    [X.data, X.vocs.feasibility_data(X.data)], axis=1, ignore_index=False\n",
    ")\n",
    "\n",
    "\n",
    "ax.plot(*history[[\"x1\", \"x2\"]][history[\"feasible\"]].to_numpy().T, \".C1\")\n",
    "ax.plot(*history[[\"x1\", \"x2\"]][~history[\"feasible\"]].to_numpy().T, \".C2\")\n",
    "\n",
    "ax.set_xlim(0, 3.14)\n",
    "ax.set_ylim(0, 3.14)\n",
    "ax.set_xlabel(\"x1\")\n",
    "ax.set_ylabel(\"x2\")\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Plot path through input space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-07-02T04:15:43.927823Z",
     "iopub.status.busy": "2022-07-02T04:15:43.927683Z",
     "iopub.status.idle": "2022-07-02T04:15:43.973044Z",
     "shell.execute_reply": "2022-07-02T04:15:43.972763Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = history.plot(\"x1\", \"x2\")\n",
    "ax.set_ylim(0, 3.14)\n",
    "ax.set_xlim(0, 3.14)\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-07-02T04:15:43.974595Z",
     "iopub.status.busy": "2022-07-02T04:15:43.974490Z",
     "iopub.status.idle": "2022-07-02T04:15:48.070949Z",
     "shell.execute_reply": "2022-07-02T04:15:48.070622Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the acquisition function\n",
    "from xopt.generators.bayesian.objectives import feasibility\n",
    "\n",
    "bounds = X.generator.vocs.bounds\n",
    "model = X.generator.model\n",
    "\n",
    "# create mesh\n",
    "n = 100\n",
    "x = torch.linspace(*bounds.T[0], n)\n",
    "y = torch.linspace(*bounds.T[1], n)\n",
    "xx, yy = torch.meshgrid(x, y)\n",
    "pts = torch.hstack([ele.reshape(-1, 1) for ele in (xx, yy)]).double()\n",
    "\n",
    "xx, yy = xx.numpy(), yy.numpy()\n",
    "\n",
    "acq_func = X.generator.get_acquisition(model)\n",
    "with torch.no_grad():\n",
    "    acq_pts = pts.unsqueeze(1)\n",
    "    acq = acq_func(acq_pts)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    c = ax.pcolor(xx, yy, acq.reshape(n, n), cmap=\"Blues\")\n",
    "    fig.colorbar(c)\n",
    "    ax.set_title(\"Acquisition function\")\n",
    "\n",
    "    ax.plot(*history[[\"x1\", \"x2\"]][history[\"feasible\"]].to_numpy().T, \".C1\")\n",
    "    ax.plot(*history[[\"x1\", \"x2\"]][~history[\"feasible\"]].to_numpy().T, \".C2\")\n",
    "\n",
    "    ax.plot(*history[[\"x1\", \"x2\"]].to_numpy()[-1].T, \"+\")\n",
    "\n",
    "    feas = feasibility(pts.unsqueeze(1), model, X.vocs).flatten()\n",
    "\n",
    "    fig2, ax2 = plt.subplots(figsize=(8,8))\n",
    "    c = ax2.pcolor(xx, yy, feas.reshape(n, n))\n",
    "    fig2.colorbar(c)\n",
    "    ax2.set_title(\"Feasible Region\")\n",
    "\n",
    "candidate = pd.DataFrame(X.generator.generate(1), index=[0])\n",
    "print(candidate[[\"x1\", \"x2\"]].to_numpy())\n",
    "ax.plot(*candidate[[\"x1\", \"x2\"]].to_numpy()[0], \"o\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72034539424920dfb606fe3b820b3f27dca0cbf1c69938110810ec4641e275b1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
